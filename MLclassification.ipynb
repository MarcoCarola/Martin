{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b933b3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import array_to_img\n",
    "from keras.utils import img_to_array\n",
    "from keras.utils import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74544935",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b122913",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3f8365",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1 Single image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2654b54f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import array_to_img, img_to_array, load_img\n",
    "from skimage import io\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "\n",
    "img = load_img('D:\\JupyterNotebook/leave.jpg') \n",
    "\n",
    "x = img_to_array(img) \n",
    "x = x.reshape((1,) + x.shape) \n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir='preview', save_prefix='leave', \n",
    "                          save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6711e2ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.2 Healthy Leaves augmentation Training seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642892b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage import io\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest') \n",
    "\n",
    "i = 0\n",
    "for batch in datagen.flow_from_directory(directory='Original_Data\\Heathly_Leaves', \n",
    "                                         batch_size=16,  \n",
    "                                         target_size=(256, 256),\n",
    "                                         color_mode=\"rgb\",\n",
    "                                         save_to_dir='preview', \n",
    "                                         save_prefix='aug', \n",
    "                                         save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 140:\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a97958-9388-4c0c-a77e-1118a69a805a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.3 Bactiral Spot Augmentation Training seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfdc120-164a-4f90-bc90-4321bb6ef941",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage import io\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest') \n",
    "\n",
    "i = 0\n",
    "for batch in datagen.flow_from_directory(directory='Original_Data\\Infected_Leaves_new\\Bacterial_Spot', \n",
    "                                         batch_size=16,  \n",
    "                                         target_size=(256, 256),\n",
    "                                         color_mode=\"rgb\",\n",
    "                                         save_to_dir='preview', \n",
    "                                         save_prefix='aug', \n",
    "                                         save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 160:\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa07273",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.4 Leave Fall augmentation Training Seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009ca18a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage import io\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest') \n",
    "\n",
    "i = 0\n",
    "for batch in datagen.flow_from_directory(directory='Original_Data\\Infected_Leaves_new\\Leave_Fall/', \n",
    "                                         batch_size=16,  \n",
    "                                         target_size=(256, 256),\n",
    "                                         color_mode=\"rgb\",\n",
    "                                         save_to_dir='preview', \n",
    "                                         save_prefix='aug', \n",
    "                                         save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 190:\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488d1231",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.5 Early Blight augmentation Training Seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f46077",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage import io\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest') \n",
    "    \n",
    "i = 0\n",
    "for batch in datagen.flow_from_directory(directory='Original_Data\\Infected_Leaves_new\\Early_blight/', \n",
    "                                         batch_size=16,  \n",
    "                                         target_size=(256, 256),\n",
    "                                         color_mode=\"rgb\",\n",
    "                                         save_to_dir='preview', \n",
    "                                         save_prefix='aug', \n",
    "                                         save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 132:\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8eec23-2c6e-4eb4-b99b-41864d94e97d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.6 Down Mildew augmentation Training Seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce374b54-c30a-4d05-b32a-1c5220fea5bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage import io\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest') \n",
    "    \n",
    "i = 0\n",
    "for batch in datagen.flow_from_directory(directory='Original_Data\\Infected_Leaves_new\\Down_Mildew/', \n",
    "                                         batch_size=16,  \n",
    "                                         target_size=(256, 256),\n",
    "                                         color_mode=\"rgb\",\n",
    "                                         save_to_dir='preview', \n",
    "                                         save_prefix='aug', \n",
    "                                         save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 128:\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39824338-ce4e-435b-b45e-fc0ff7514345",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.7 Healthy Leaves augmentation Validation seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047fd21b-50cb-4c23-997c-d36e035da520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage import io\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest') \n",
    "\n",
    "i = 0\n",
    "for batch in datagen.flow_from_directory(directory='Original_Data\\Heathly_Leaves', \n",
    "                                         batch_size=16,  \n",
    "                                         target_size=(256, 256),\n",
    "                                         color_mode=\"rgb\",\n",
    "                                         save_to_dir='preview', \n",
    "                                         save_prefix='aug', \n",
    "                                         save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 18:\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c6569d-ede6-4506-8139-59a39b78ee08",
   "metadata": {},
   "source": [
    "## 1.8 Bactiral Spot Augmentation Validation seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c696d6-b433-4638-9746-908a8fb0221e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage import io\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest') \n",
    "\n",
    "i = 0\n",
    "for batch in datagen.flow_from_directory(directory='Original_Data\\Infected_Leaves_new\\Bacterial_Spot', \n",
    "                                         batch_size=16,  \n",
    "                                         target_size=(256, 256),\n",
    "                                         color_mode=\"rgb\",\n",
    "                                         save_to_dir='preview', \n",
    "                                         save_prefix='aug', \n",
    "                                         save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 21:\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee1871d-7b64-422e-92aa-dbcdf6d28eb1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.9 Leave Fall augmentation Validation Seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7c51c9-dd7c-4330-8546-34cdfebe28e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage import io\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest') \n",
    "\n",
    "i = 0\n",
    "for batch in datagen.flow_from_directory(directory='Original_Data\\Infected_Leaves_new\\Leave_Fall/', \n",
    "                                         batch_size=16,  \n",
    "                                         target_size=(256, 256),\n",
    "                                         color_mode=\"rgb\",\n",
    "                                         save_to_dir='preview', \n",
    "                                         save_prefix='aug', \n",
    "                                         save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 25:\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca81194d-5b4d-405f-a110-f369d3dd2fbb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.10 Early Blight augmentation Validation Seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e24acf3-7027-4636-bef1-43aff0786df1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage import io\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest') \n",
    "    \n",
    "i = 0\n",
    "for batch in datagen.flow_from_directory(directory='Original_Data\\Infected_Leaves_new\\Early_blight/', \n",
    "                                         batch_size=16,  \n",
    "                                         target_size=(256, 256),\n",
    "                                         color_mode=\"rgb\",\n",
    "                                         save_to_dir='preview', \n",
    "                                         save_prefix='aug', \n",
    "                                         save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 18:\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3295ff4f-5083-4ea7-a8ae-ebe4c0dce7dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.11 Down Mildew augmentation Validation Seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6da3c3-b611-48dd-b691-370f4911b13e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage import io\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest') \n",
    "    \n",
    "i = 0\n",
    "for batch in datagen.flow_from_directory(directory='Original_Data\\Infected_Leaves_new\\Down_Mildew/', \n",
    "                                         batch_size=16,  \n",
    "                                         target_size=(256, 256),\n",
    "                                         color_mode=\"rgb\",\n",
    "                                         save_to_dir='preview', \n",
    "                                         save_prefix='aug', \n",
    "                                         save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 16:\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79745bdc",
   "metadata": {
    "tags": []
   },
   "source": [
    "##  1.12 Multy class folder augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9777822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage import io\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=45,     \n",
    "        width_shift_range=0.2,  \n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest', cval=0)    \n",
    "\n",
    "i = 0\n",
    "for batch in datagen.flow_from_directory(directory='Leaves/', \n",
    "                                         batch_size=16,  \n",
    "                                         target_size=(256, 256),\n",
    "                                         color_mode=\"rgb\",\n",
    "                                         save_to_dir='preview', \n",
    "                                         save_prefix='aug', \n",
    "                                         save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 31:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d78d2d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17f8b4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sn; sn.set(font_scale=1.4)\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb9855e",
   "metadata": {},
   "source": [
    "# 3. Image Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01f8e039",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e38543b-3f8e-4d1b-aaf2-105cc2835058",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef56fa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Heathly_Leaves', 'Bacterial_Spot', 'Down_Mildew', 'Early_blight', 'Leave_Fall' ]\n",
    "class_names_label = {class_name: i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "nb_classes = len(class_names)\n",
    "\n",
    "print(class_names_label)\n",
    "\n",
    "IMAGE_SIZE = (256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e289a5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    DIRECTORY = r\"D:\\JupyterNotebook\\Augmented_Data\"\n",
    "    CATEGORY = [\"seg_train\", \"seg_validation\"]\n",
    "    \n",
    "    output = []\n",
    "    \n",
    "    for category in CATEGORY:\n",
    "        path = os.path.join(DIRECTORY, category)\n",
    "        print(path)\n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        print(\"Loading {}\".format(category))\n",
    "        \n",
    "        for folder in os.listdir(path):\n",
    "            label = class_names_label[folder]\n",
    "            \n",
    "            # Iterate through each image in our folder\n",
    "            for file in os.listdir(os.path.join(path,folder)):\n",
    "                \n",
    "                # Get the path name of the image\n",
    "                img_path = os.path.join(os.path.join(path, folder), file)\n",
    "                \n",
    "                # Open and resize the img\n",
    "                image = cv2.imread(img_path)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                image = cv2.resize(image, IMAGE_SIZE)\n",
    "                \n",
    "                # Append the image and its corresponding label to the output\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "                \n",
    "        images = np.array(images, dtype = 'float32')\n",
    "        labels = np.array(labels, dtype = 'int32')\n",
    "        \n",
    "        output.append((images, labels))\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa0707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (valid_images, valid_labels) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6f98ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = shuffle(train_images, train_labels, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd012c0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def display_examples(class_names, images, labels):\n",
    "    \n",
    "    figsize = (20, 20)\n",
    "    fig = plt.figure(figsize = figsize)\n",
    "    fig.suptitle(\"Some examples of images of the dataset\", fontsize = 16)\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i].astype(np.uint8))\n",
    "        plt.xlabel(class_names[labels[i]])\n",
    "    plt.show()\n",
    "display_examples(class_names, train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5920ebed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (256, 256, 3)),\n",
    "    tf.keras.layers.MaxPooling2D (2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D (2,2),\n",
    "    tf.keras.layers. Flatten(),\n",
    "    tf.keras.layers.Dense (128, activation = tf.nn.relu), \n",
    "    tf.keras.layers.Dense(5, activation = tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350c8fb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07cf77e-7c18-4fa2-a1de-c6f0ae937a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1f2a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_images, train_labels, batch_size = 8, epochs = 4, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cdc452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_loss (history):\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(221) \n",
    "    plt.plot(history.history['accuracy'], 'bo--', label = \"acc\") \n",
    "    plt.plot(history.history['val_accuracy'], 'ro-', label = \"val_acc\")\n",
    "    plt.title(\"train_acc vs val_acc\")\n",
    "    plt.ylabel(\"accuracy\")    \n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot loss function\n",
    "    plt.subplot(222)\n",
    "    plt.plot(history.history['loss'], 'bo--', label = \"loss\") \n",
    "    plt.plot(history.history['val_loss'], 'ro--', label = \"val_loss\")\n",
    "    plt.title(\"train_loss vs val_loss\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5fc089",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_loss(history)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5da64e56-e40d-4f3a-8b52-2c5df8ae3a1f",
   "metadata": {},
   "source": [
    "valid_loss = model.evaluate(valid_images, valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da136ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(valid_images) \n",
    "pred_labels = np.argmax(predictions, axis = 1)\n",
    "print(classification_report(valid_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6441c701",
   "metadata": {},
   "source": [
    "# 4. Using VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c503b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model\n",
    "\n",
    "model = VGG16(weights = 'imagenet', include_top = False)\n",
    "model = Model(inputs = model.inputs, outputs = model.layers[-5].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9d2851-8ab5-4c4b-a0f3-f1dcd977761e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tf.debugging.disable_traceback_filtering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98eafd3-8d77-465f-bf9d-7bcf7e823834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tftrain_images\n",
    "\n",
    "# Place the input tensors on the CPU\n",
    "with tf.device('/CPU:0'):\n",
    "    train_images_cpu = tf.convert_to_tensor(train_images)\n",
    "    train_labels_cpu = tf.convert_to_tensor(train_labels)\n",
    "    valid_images_cpu = tf.convert_to_tensor(valid_images)\n",
    "\n",
    "# Now use the CPU tensors for predictiontrain_images\n",
    "train_features = model.predict(train_images_cpu)\n",
    "valid_features = model.predict(valid_images_cpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120deca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = model.predict(train_images)\n",
    "valid_features = model.predict(valid_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f67a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, Activation, MaxPooling2D, Flatten\n",
    "\n",
    "model2 = VGG16(weights = 'imagenet', include_top = False)\n",
    "\n",
    "input_shape = model2.layers[-4].get_input_shape_at (0) # get the input shape of desired layer\n",
    "layer_input = Input (shape = (9, 9, 512)) # a new input tensor to be able to feed the desired Layer \n",
    "\n",
    "x = layer_input \n",
    "for layer in model2.layers[-4::1]:\n",
    "    x = layer(x)\n",
    "\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D (pool_size = (2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(100, activation ='relu')(x)\n",
    "x = Dense(6,activation = 'softmax')(x)\n",
    "\n",
    "# create the model\n",
    "\n",
    "new_model = Model (layer_input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649dab80",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfe9301",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = new_model.fit(train_features, train_labels, batch_size = 128, epochs = 8, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a673f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4286ac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions = new_model.predict(valid_features)\n",
    "pred_labels = np.argmax(predictions, axis = 1)\n",
    "print(\"Accuracy : {}\".format(accuracy_score(valid_labels, pred_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613e6437-3232-46ac-8cf1-d1a81233d2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
